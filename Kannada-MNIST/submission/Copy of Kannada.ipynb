{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Kannada.ipynb","provenance":[{"file_id":"1Z1a6N2UdCv6Dvpmt4tU7YSL-9t8ObkWb","timestamp":1578015506324}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1eFqzKjin3pn","colab_type":"text"},"source":["#1.Data Preprocessing\n","\n","Read two training csv files into one pandas dataframe, create custom Pytorch Dataset for training, validation, and testing sets, and read all into dataloaders"]},{"cell_type":"code","metadata":{"id":"ojyjziitBxWV","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch\n","import torch.optim as optim\n","from torch.autograd import Variable as var\n","from torchvision.models import densenet121\n","import torchvision"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rOKKqb_Hr2HV","colab":{}},"source":["test_df = pd.read_csv('test.csv')\n","train_df = pd.read_csv('train.csv')\n","additional_train_df = pd.read_csv('Dig-MNIST.csv')\n","train_df = train_df.append(additional_train_df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9_m-U5Mnq5_","colab_type":"code","colab":{}},"source":["imgs = train_df.iloc[:,1:]\n","labels = train_df['label']\n","#sklearn's train_test_split is a much simpler function we can use to create a training/validation set than using \n","#Pytorch's torch.utils.data.random_split function\n","train_x,val_x,train_label,val_label = train_test_split(imgs,labels,test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7eB66cWbt1h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":266},"outputId":"6fea4a72-3e7c-4d83-9fbe-abfc21a12ac7","executionInfo":{"status":"ok","timestamp":1578038679233,"user_tz":360,"elapsed":271,"user":{"displayName":"Jonathan Hrach","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvQOBdkCsJ8wR615JkhkNVRVrDOP8rjSLHRJ2lAQ=s64","userId":"12030830714702100809"}}},"source":["print(test_df.iloc[:,1:])"],"execution_count":117,"outputs":[{"output_type":"stream","text":["      pixel0  pixel1  pixel2  pixel3  ...  pixel780  pixel781  pixel782  pixel783\n","0          0       0       0       0  ...         0         0         0         0\n","1          0       0       0       0  ...         0         0         0         0\n","2          0       0       0       0  ...         0         0         0         0\n","3          0       0       0       0  ...         0         0         0         0\n","4          0       0       0       0  ...         0         0         0         0\n","...      ...     ...     ...     ...  ...       ...       ...       ...       ...\n","4995       0       0       0       0  ...         0         0         0         0\n","4996       0       0       0       0  ...         0         0         0         0\n","4997       0       0       0       0  ...         0         0         0         0\n","4998       0       0       0       0  ...         0         0         0         0\n","4999       0       0       0       0  ...         0         0         0         0\n","\n","[5000 rows x 784 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EMKXRRRXrLhw","colab":{}},"source":["class ds(Dataset):\n","    def __init__(self,imgs,labels,transform,train_test):\n","        self.train_test = train_test\n","        if self.train_test:\n","            self.train_imgs = np.asarray(imgs)\n","            self.train_labels = np.asarray(labels)\n","            self.train_len = len(self.train_imgs)\n","        else:\n","            self.test_imgs = imgs\n","            self.test_len = len(self.test_imgs)\n","        self.transform = transform\n","    def __len__(self):\n","        if self.train_test:\n","            return self.train_len\n","        else:\n","            return self.test_len\n","    def __getitem__(self,index):\n","        if self.train_test:\n","            img = self.train_imgs[index]\n","            label = self.train_labels[index]\n","            img = np.asarray(img).reshape(28,28).astype('uint8')\n","            img = Image.fromarray(img).convert('L')\n","            if self.transform is not None:\n","                img = self.transform(img)\n","            return (img,label)\n","        else:\n","            img = self.test_imgs[index]\n","            img = np.asarray(img).reshape(28,28).astype('uint8')\n","            img = Image.fromarray(img).convert('L')\n","            if self.transform is not None:\n","                img = self.transform(img)\n","            return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wm79hxUPX5a0","colab_type":"code","colab":{}},"source":["class ds2(Dataset):\n","    def __init__(self,imgs,labels,transform,train_test):\n","        self.train_test = train_test\n","        if self.train_test:\n","            self.train_imgs = np.asarray(imgs)\n","            self.train_labels = np.asarray(labels)\n","            self.train_len = len(self.train_imgs)\n","        else:\n","            self.test_imgs = np.asarray(imgs)\n","            self.test_len = len(self.test_imgs)\n","        self.transform = transform\n","    def __len__(self):\n","        if self.train_test:\n","            return self.train_len\n","        else:\n","            return self.test_len\n","    def __getitem__(self,index):\n","        if self.train_test:\n","            img = self.train_imgs[index]\n","            label = self.train_labels[index]\n","            img = np.asarray(img).reshape(28,28).astype('uint8')\n","            img = Image.fromarray(img).convert('RGB')\n","            if self.transform is not None:\n","                img = self.transform(img)\n","            return (img,label)\n","        else:\n","            img = self.test_imgs[index]\n","            img = np.asarray(img).reshape(28,28).astype('uint8')\n","            img = Image.fromarray(img).convert('RGB')\n","            if self.transform is not None:\n","                img = self.transform(img)\n","            return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"67L3DbrtrMjh","colab_type":"code","colab":{}},"source":["transform = transforms.Compose([\n","    transforms.ToTensor(),     \n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UItmdUm-DZWh","colab_type":"code","colab":{}},"source":["transform_aug = transforms.Compose([\n","    transforms.RandomCrop(28),\n","    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n","    transforms.ToTensor(),     \n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ECguIza-sOIS","colab":{}},"source":["train_ds = ds(train_x,train_label,transform_aug,True)\n","val_ds = ds(val_x,val_label,transform,True)\n","test_ds = ds(test_df.iloc[:,1:],None,transform,False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Q40n465aXob","colab_type":"code","colab":{}},"source":["train_ds2 = ds2(train_x,train_label,transform_aug,True)\n","val_ds2 = ds2(val_x,val_label,transform,True)\n","test_ds2 = ds2(test_df.iloc[:,1:],None,transform,False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5lj7w7Nsr7_S","colab_type":"code","colab":{}},"source":["batch_size = 32\n","train_dl = DataLoader(train_ds2,batch_size=batch_size,shuffle=True)\n","val_dl = DataLoader(val_ds2,batch_size=batch_size,shuffle=False)\n","test_dl = DataLoader(test_ds2,batch_size=5000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RgblKWmrsnMB","colab_type":"text"},"source":["#2.Define Model\n","\n","Training a CNN with a simple architecture similar to what achieves 97-98% validation accuracy on MNIST will not perform as well on the Kannada dataset. To achieve higher accuracy, let us finetune a pretrained CNN.                          https://arxiv.org/ftp/arxiv/papers/1901/1901.06032.pdf#page=17 Shows a list of some different CNN architectures, most of which are available to be used on PyTorch!"]},{"cell_type":"code","metadata":{"id":"6n7ds3YgspEM","colab_type":"code","colab":{}},"source":["#Similar to what I implemented for MINST, but does not perform as well! Also is very inconsistent as far as accuracy\n","#goes.\n","class mycnn(nn.Module):\n","    def __init__(self):\n","        super(mycnn,self).__init__()\n","        self.cnn1 = nn.Conv2d(1,3,5)\n","        self.cnn2 = nn.Conv2d(3,2,5)\n","        self.linear = nn.Linear(800,400)\n","        self.linear2 = nn.Linear(400,10)\n","        self.dropout = nn.Dropout()\n","        self.relu = nn.ReLU()\n","    def forward(self,x):\n","        n = x.size()[0]\n","        #print('input size:',x.size())\n","        x = self.relu(self.cnn1(x))\n","        #print('x output size:',x.size())\n","        x = self.relu(self.cnn2(x))\n","        #print('output size:',x.size())\n","        x = x.view(n,-1)\n","        #print('size of x:',x.size())\n","        x = self.relu(self.linear(self.dropout(x)))\n","        return x\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QN1-aoqlS3Tb","colab_type":"text"},"source":["Let use use DenseNet. Note below that the CNN is expecting RGB images, and changing the input channels to 3 would render the rest of the weights useless. Therefore, we need to make our grayscale images appear RGB by repeating the input image 3 times on a new dimension!"]},{"cell_type":"code","metadata":{"id":"ZYcE__KlRli8","colab_type":"code","outputId":"8347fb4c-3902-4196-e7db-d9503d41bdf9","executionInfo":{"status":"ok","timestamp":1578032373977,"user_tz":360,"elapsed":4734,"user":{"displayName":"Jonathan Hrach","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvQOBdkCsJ8wR615JkhkNVRVrDOP8rjSLHRJ2lAQ=s64","userId":"12030830714702100809"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["densenet121(pretrained=True)"],"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DenseNet(\n","  (features): Sequential(\n","    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu0): ReLU(inplace=True)\n","    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (denseblock1): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition1): _Transition(\n","      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock2): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition2): _Transition(\n","      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock3): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer17): _DenseLayer(\n","        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer18): _DenseLayer(\n","        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer19): _DenseLayer(\n","        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer20): _DenseLayer(\n","        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer21): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer22): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer23): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer24): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition3): _Transition(\n","      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock4): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":98}]},{"cell_type":"code","metadata":{"id":"fhIznDDYRtZq","colab_type":"code","outputId":"b6edeac7-84b7-4933-ea59-e8684a06ce3f","executionInfo":{"status":"ok","timestamp":1578032374279,"user_tz":360,"elapsed":5007,"user":{"displayName":"Jonathan Hrach","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvQOBdkCsJ8wR615JkhkNVRVrDOP8rjSLHRJ2lAQ=s64","userId":"12030830714702100809"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["a = densenet121(pretrained=True)\n","print(a.classifier)"],"execution_count":99,"outputs":[{"output_type":"stream","text":["Linear(in_features=1024, out_features=1000, bias=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ku2kXgwtwFJl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0b382a59-d8b0-4d64-bf01-5a3b8826a485","executionInfo":{"status":"ok","timestamp":1578032374281,"user_tz":360,"elapsed":4993,"user":{"displayName":"Jonathan Hrach","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvQOBdkCsJ8wR615JkhkNVRVrDOP8rjSLHRJ2lAQ=s64","userId":"12030830714702100809"}}},"source":["a.classifier.in_features"],"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1024"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"code","metadata":{"id":"cMgG4O76SXdU","colab_type":"code","outputId":"218b730b-f76c-4da1-a841-cd94a49bf87e","executionInfo":{"status":"ok","timestamp":1578032374283,"user_tz":360,"elapsed":4974,"user":{"displayName":"Jonathan Hrach","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvQOBdkCsJ8wR615JkhkNVRVrDOP8rjSLHRJ2lAQ=s64","userId":"12030830714702100809"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(a.features.conv0)"],"execution_count":101,"outputs":[{"output_type":"stream","text":["Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wZ76WtXiduom","colab_type":"code","colab":{}},"source":["class densenet(nn.Module):\n","    def __init__(self):\n","        super(densenet,self).__init__()\n","        self.densenet = densenet121(pretrained=True)\n","        #self.densenet.features.conv0 = Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        for param in self.densenet.parameters():\n","            param.requires_grad = False\n","        #https://github.com/pytorch/vision/issues/1231\n","        #https://github.com/pytorch/pytorch/pull/22304\n","        #Issue with H,W size here, so add these lines of code to resolve!\n","        for x in self.densenet.modules():\n","            if isinstance(x, nn.AvgPool2d):\n","                x.ceil_mode = True\n","        self.densenet.classifier = nn.Sequential(nn.Linear(1024,10))\n","        for m in self.densenet.classifier:\n","            torch.nn.init.kaiming_normal_(m.weight)\n","        #print(self.densenet)\n","    def forward(self,x):\n","        return self.densenet.forward(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WMBWBXu_mfkO","colab_type":"text"},"source":["#3.Training"]},{"cell_type":"code","metadata":{"id":"MgU6EPLLmiHE","colab_type":"code","colab":{}},"source":["n_epoch = 25\n","lr = 1e-3\n","net = densenet().cuda()\n","#net = mycnn().cuda()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(),lr=lr)\n","n_print = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z10sh4p0py54","colab_type":"code","colab":{}},"source":["def validate(model,data):\n","  # To get validation accuracy = (correct/total)*100.\n","  total = 0\n","  correct = 0\n","  for i,(images,labels) in enumerate(data):\n","    images = var(images.cuda())\n","    x = model(images)\n","    value,pred = torch.max(x,1)\n","    pred = pred.data.cpu()\n","    total += x.size(0)\n","    correct += torch.sum(pred == labels)\n","  return correct*100./total"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yhsjknXrmsHl","colab_type":"code","outputId":"dd6f37e4-7e63-4037-ff6d-21e79842262f","executionInfo":{"status":"ok","timestamp":1578038206151,"user_tz":360,"elapsed":4004696,"user":{"displayName":"Jonathan Hrach","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvQOBdkCsJ8wR615JkhkNVRVrDOP8rjSLHRJ2lAQ=s64","userId":"12030830714702100809"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for e in range(n_epoch):\n","  for i,(images,labels) in enumerate(train_dl):\n","    images = var(images.cuda())\n","    labels = var(labels.cuda())\n","    optimizer.zero_grad()\n","    pred = net(images)\n","    loss = criterion(pred,labels)\n","    loss.backward()\n","    optimizer.step()\n","    if (i+1) % n_print == 0:\n","      accuracy = float(validate(net,val_dl))\n","      print('Epoch :',e+1,'Batch :',i+1,'Loss :',float(loss.data),'Accuracy :',accuracy,'%')\n"],"execution_count":105,"outputs":[{"output_type":"stream","text":["Epoch : 1 Batch : 100 Loss : 1.7385153770446777 Accuracy : 44.17710876464844 %\n","Epoch : 1 Batch : 200 Loss : 1.3519468307495117 Accuracy : 58.11503601074219 %\n","Epoch : 1 Batch : 300 Loss : 1.2034697532653809 Accuracy : 63.68878173828125 %\n","Epoch : 1 Batch : 400 Loss : 1.2892407178878784 Accuracy : 67.59680938720703 %\n","Epoch : 1 Batch : 500 Loss : 1.2625585794448853 Accuracy : 69.45472717285156 %\n","Epoch : 1 Batch : 600 Loss : 0.8023688197135925 Accuracy : 70.50113677978516 %\n","Epoch : 1 Batch : 700 Loss : 0.9457569122314453 Accuracy : 72.23804473876953 %\n","Epoch : 1 Batch : 800 Loss : 1.0544648170471191 Accuracy : 73.12784576416016 %\n","Epoch : 1 Batch : 900 Loss : 0.7599385380744934 Accuracy : 73.73291778564453 %\n","Epoch : 1 Batch : 1000 Loss : 1.3845926523208618 Accuracy : 73.88951873779297 %\n","Epoch : 1 Batch : 1100 Loss : 0.834579348564148 Accuracy : 73.29157257080078 %\n","Epoch : 1 Batch : 1200 Loss : 1.1266205310821533 Accuracy : 74.2525634765625 %\n","Epoch : 1 Batch : 1300 Loss : 0.8298630118370056 Accuracy : 74.65831756591797 %\n","Epoch : 1 Batch : 1400 Loss : 1.1126748323440552 Accuracy : 74.83627319335938 %\n","Epoch : 1 Batch : 1500 Loss : 0.6572409272193909 Accuracy : 75.46981811523438 %\n","Epoch : 1 Batch : 1600 Loss : 1.2660950422286987 Accuracy : 75.59082794189453 %\n","Epoch : 1 Batch : 1700 Loss : 0.9188506603240967 Accuracy : 75.9467544555664 %\n","Epoch : 2 Batch : 100 Loss : 0.8726660013198853 Accuracy : 76.65148162841797 %\n","Epoch : 2 Batch : 200 Loss : 1.3152977228164673 Accuracy : 76.70130920410156 %\n","Epoch : 2 Batch : 300 Loss : 0.6573279500007629 Accuracy : 76.50199127197266 %\n","Epoch : 2 Batch : 400 Loss : 1.1335692405700684 Accuracy : 76.93621826171875 %\n","Epoch : 2 Batch : 500 Loss : 0.6752576231956482 Accuracy : 77.14977264404297 %\n","Epoch : 2 Batch : 600 Loss : 0.9787548184394836 Accuracy : 77.3134994506836 %\n","Epoch : 2 Batch : 700 Loss : 0.9160406589508057 Accuracy : 76.5589370727539 %\n","Epoch : 2 Batch : 800 Loss : 1.0811333656311035 Accuracy : 76.87215423583984 %\n","Epoch : 2 Batch : 900 Loss : 0.7694715261459351 Accuracy : 77.34909057617188 %\n","Epoch : 2 Batch : 1000 Loss : 1.0054606199264526 Accuracy : 76.91486358642578 %\n","Epoch : 2 Batch : 1100 Loss : 0.7621368169784546 Accuracy : 77.55552673339844 %\n","Epoch : 2 Batch : 1200 Loss : 0.7957572937011719 Accuracy : 77.99686431884766 %\n","Epoch : 2 Batch : 1300 Loss : 0.8417083621025085 Accuracy : 77.30638122558594 %\n","Epoch : 2 Batch : 1400 Loss : 0.599178671836853 Accuracy : 77.81890869140625 %\n","Epoch : 2 Batch : 1500 Loss : 0.7173012495040894 Accuracy : 78.13211822509766 %\n","Epoch : 2 Batch : 1600 Loss : 1.1574140787124634 Accuracy : 77.16400909423828 %\n","Epoch : 2 Batch : 1700 Loss : 0.8968790769577026 Accuracy : 77.24942779541016 %\n","Epoch : 3 Batch : 100 Loss : 0.586796224117279 Accuracy : 78.3100814819336 %\n","Epoch : 3 Batch : 200 Loss : 0.7729185223579407 Accuracy : 77.97550964355469 %\n","Epoch : 3 Batch : 300 Loss : 0.6619405746459961 Accuracy : 78.21753692626953 %\n","Epoch : 3 Batch : 400 Loss : 0.8444192409515381 Accuracy : 78.125 %\n","Epoch : 3 Batch : 500 Loss : 1.1261543035507202 Accuracy : 78.35990905761719 %\n","Epoch : 3 Batch : 600 Loss : 0.9411485195159912 Accuracy : 77.21383666992188 %\n","Epoch : 3 Batch : 700 Loss : 0.5980302691459656 Accuracy : 77.90432739257812 %\n","Epoch : 3 Batch : 800 Loss : 0.9624068140983582 Accuracy : 78.6731185913086 %\n","Epoch : 3 Batch : 900 Loss : 0.5260185599327087 Accuracy : 78.08940887451172 %\n","Epoch : 3 Batch : 1000 Loss : 0.6997459530830383 Accuracy : 78.95785522460938 %\n","Epoch : 3 Batch : 1100 Loss : 1.0982627868652344 Accuracy : 78.68023681640625 %\n","Epoch : 3 Batch : 1200 Loss : 0.8028779029846191 Accuracy : 78.3100814819336 %\n","Epoch : 3 Batch : 1300 Loss : 0.7168213129043579 Accuracy : 78.81549072265625 %\n","Epoch : 3 Batch : 1400 Loss : 1.0279415845870972 Accuracy : 79.03616333007812 %\n","Epoch : 3 Batch : 1500 Loss : 0.8346033096313477 Accuracy : 78.97921752929688 %\n","Epoch : 3 Batch : 1600 Loss : 0.5166323184967041 Accuracy : 78.76566314697266 %\n","Epoch : 3 Batch : 1700 Loss : 0.9203781485557556 Accuracy : 78.65176391601562 %\n","Epoch : 4 Batch : 100 Loss : 0.7529847025871277 Accuracy : 79.1856460571289 %\n","Epoch : 4 Batch : 200 Loss : 0.640583872795105 Accuracy : 78.623291015625 %\n","Epoch : 4 Batch : 300 Loss : 0.9536118507385254 Accuracy : 78.55210876464844 %\n","Epoch : 4 Batch : 400 Loss : 0.6155116558074951 Accuracy : 78.89379119873047 %\n","Epoch : 4 Batch : 500 Loss : 0.7835174202919006 Accuracy : 79.56292724609375 %\n","Epoch : 4 Batch : 600 Loss : 0.6966556310653687 Accuracy : 79.34225463867188 %\n","Epoch : 4 Batch : 700 Loss : 1.1962857246398926 Accuracy : 79.44190979003906 %\n","Epoch : 4 Batch : 800 Loss : 0.8360745906829834 Accuracy : 79.47750854492188 %\n","Epoch : 4 Batch : 900 Loss : 0.6412907838821411 Accuracy : 79.64122772216797 %\n","Epoch : 4 Batch : 1000 Loss : 0.781933069229126 Accuracy : 79.07887268066406 %\n","Epoch : 4 Batch : 1100 Loss : 1.3697341680526733 Accuracy : 79.47039031982422 %\n","Epoch : 4 Batch : 1200 Loss : 1.167431354522705 Accuracy : 78.3741455078125 %\n","Epoch : 4 Batch : 1300 Loss : 1.1704620122909546 Accuracy : 78.5592269897461 %\n","Epoch : 4 Batch : 1400 Loss : 0.6641868352890015 Accuracy : 78.8724365234375 %\n","Epoch : 4 Batch : 1500 Loss : 1.1653038263320923 Accuracy : 79.3208999633789 %\n","Epoch : 4 Batch : 1600 Loss : 0.6032847762107849 Accuracy : 79.33513641357422 %\n","Epoch : 4 Batch : 1700 Loss : 0.6224132776260376 Accuracy : 79.79783630371094 %\n","Epoch : 5 Batch : 100 Loss : 0.6411969661712646 Accuracy : 80.03986358642578 %\n","Epoch : 5 Batch : 200 Loss : 0.6097415685653687 Accuracy : 79.6910629272461 %\n","Epoch : 5 Batch : 300 Loss : 0.6237224340438843 Accuracy : 80.06121826171875 %\n","Epoch : 5 Batch : 400 Loss : 0.8152419924736023 Accuracy : 79.77648162841797 %\n","Epoch : 5 Batch : 500 Loss : 0.9174465537071228 Accuracy : 79.52733612060547 %\n","Epoch : 5 Batch : 600 Loss : 0.7807444930076599 Accuracy : 79.65546417236328 %\n","Epoch : 5 Batch : 700 Loss : 0.7332101464271545 Accuracy : 80.41002655029297 %\n","Epoch : 5 Batch : 800 Loss : 0.6273072361946106 Accuracy : 79.9544448852539 %\n","Epoch : 5 Batch : 900 Loss : 0.7832314372062683 Accuracy : 79.47039031982422 %\n","Epoch : 5 Batch : 1000 Loss : 0.3348693549633026 Accuracy : 79.32801818847656 %\n","Epoch : 5 Batch : 1100 Loss : 0.5418833494186401 Accuracy : 79.84054565429688 %\n","Epoch : 5 Batch : 1200 Loss : 0.7947587966918945 Accuracy : 79.00057220458984 %\n","Epoch : 5 Batch : 1300 Loss : 0.7439398169517517 Accuracy : 79.44190979003906 %\n","Epoch : 5 Batch : 1400 Loss : 0.7584720849990845 Accuracy : 80.07545471191406 %\n","Epoch : 5 Batch : 1500 Loss : 0.8656390905380249 Accuracy : 80.23918151855469 %\n","Epoch : 5 Batch : 1600 Loss : 0.7712321877479553 Accuracy : 80.32460021972656 %\n","Epoch : 5 Batch : 1700 Loss : 0.9023451209068298 Accuracy : 80.32460021972656 %\n","Epoch : 6 Batch : 100 Loss : 0.8968932628631592 Accuracy : 80.31036376953125 %\n","Epoch : 6 Batch : 200 Loss : 0.6169958710670471 Accuracy : 80.31036376953125 %\n","Epoch : 6 Batch : 300 Loss : 0.8689976930618286 Accuracy : 80.17511749267578 %\n","Epoch : 6 Batch : 400 Loss : 1.0052158832550049 Accuracy : 80.38154602050781 %\n","Epoch : 6 Batch : 500 Loss : 1.1007359027862549 Accuracy : 80.65205383300781 %\n","Epoch : 6 Batch : 600 Loss : 0.6831569671630859 Accuracy : 80.77306365966797 %\n","Epoch : 6 Batch : 700 Loss : 0.5447543859481812 Accuracy : 80.33883666992188 %\n","Epoch : 6 Batch : 800 Loss : 0.5925549268722534 Accuracy : 80.31036376953125 %\n","Epoch : 6 Batch : 900 Loss : 0.3567456603050232 Accuracy : 80.09680938720703 %\n","Epoch : 6 Batch : 1000 Loss : 0.6973574161529541 Accuracy : 80.90119934082031 %\n","Epoch : 6 Batch : 1100 Loss : 0.5385428071022034 Accuracy : 80.60221862792969 %\n","Epoch : 6 Batch : 1200 Loss : 0.9344689249992371 Accuracy : 80.01850891113281 %\n","Epoch : 6 Batch : 1300 Loss : 0.36707165837287903 Accuracy : 80.6876449584961 %\n","Epoch : 6 Batch : 1400 Loss : 0.8956491947174072 Accuracy : 80.31036376953125 %\n","Epoch : 6 Batch : 1500 Loss : 0.9912058711051941 Accuracy : 79.91172790527344 %\n","Epoch : 6 Batch : 1600 Loss : 0.9738541841506958 Accuracy : 80.85136413574219 %\n","Epoch : 6 Batch : 1700 Loss : 0.6091638207435608 Accuracy : 79.9188461303711 %\n","Epoch : 7 Batch : 100 Loss : 0.6275571584701538 Accuracy : 80.73747253417969 %\n","Epoch : 7 Batch : 200 Loss : 0.7306069731712341 Accuracy : 80.32460021972656 %\n","Epoch : 7 Batch : 300 Loss : 0.3147278428077698 Accuracy : 80.60933685302734 %\n","Epoch : 7 Batch : 400 Loss : 0.750110924243927 Accuracy : 80.97238159179688 %\n","Epoch : 7 Batch : 500 Loss : 0.7216005921363831 Accuracy : 80.8656005859375 %\n","Epoch : 7 Batch : 600 Loss : 0.6846685409545898 Accuracy : 80.73747253417969 %\n","Epoch : 7 Batch : 700 Loss : 0.7312133312225342 Accuracy : 80.55950927734375 %\n","Epoch : 7 Batch : 800 Loss : 0.47504153847694397 Accuracy : 81.24288177490234 %\n","Epoch : 7 Batch : 900 Loss : 0.5324161052703857 Accuracy : 81.09339141845703 %\n","Epoch : 7 Batch : 1000 Loss : 0.688247561454773 Accuracy : 81.15034484863281 %\n","Epoch : 7 Batch : 1100 Loss : 0.5484396815299988 Accuracy : 80.41714477539062 %\n","Epoch : 7 Batch : 1200 Loss : 0.6264362931251526 Accuracy : 81.09339141845703 %\n","Epoch : 7 Batch : 1300 Loss : 1.0759354829788208 Accuracy : 80.90119934082031 %\n","Epoch : 7 Batch : 1400 Loss : 0.7423098087310791 Accuracy : 81.07915496826172 %\n","Epoch : 7 Batch : 1500 Loss : 0.3486190736293793 Accuracy : 80.41002655029297 %\n","Epoch : 7 Batch : 1600 Loss : 1.1607110500335693 Accuracy : 80.64492797851562 %\n","Epoch : 7 Batch : 1700 Loss : 0.746238112449646 Accuracy : 80.90119934082031 %\n","Epoch : 8 Batch : 100 Loss : 0.9597539305686951 Accuracy : 80.38866424560547 %\n","Epoch : 8 Batch : 200 Loss : 0.626153826713562 Accuracy : 80.8656005859375 %\n","Epoch : 8 Batch : 300 Loss : 0.8135766983032227 Accuracy : 81.07915496826172 %\n","Epoch : 8 Batch : 400 Loss : 0.8286862373352051 Accuracy : 80.71611785888672 %\n","Epoch : 8 Batch : 500 Loss : 0.3392811417579651 Accuracy : 80.46697235107422 %\n","Epoch : 8 Batch : 600 Loss : 0.72044438123703 Accuracy : 81.00797271728516 %\n","Epoch : 8 Batch : 700 Loss : 0.6528289318084717 Accuracy : 80.85136413574219 %\n","Epoch : 8 Batch : 800 Loss : 0.714721143245697 Accuracy : 80.62357330322266 %\n","Epoch : 8 Batch : 900 Loss : 0.7349998950958252 Accuracy : 81.4493179321289 %\n","Epoch : 8 Batch : 1000 Loss : 0.6586589813232422 Accuracy : 79.62699127197266 %\n","Epoch : 8 Batch : 1100 Loss : 0.7905763983726501 Accuracy : 81.0506820678711 %\n","Epoch : 8 Batch : 1200 Loss : 0.44931215047836304 Accuracy : 80.99373626708984 %\n","Epoch : 8 Batch : 1300 Loss : 0.43058350682258606 Accuracy : 81.42796325683594 %\n","Epoch : 8 Batch : 1400 Loss : 0.6733567714691162 Accuracy : 81.10050964355469 %\n","Epoch : 8 Batch : 1500 Loss : 0.7540075182914734 Accuracy : 80.8015365600586 %\n","Epoch : 8 Batch : 1600 Loss : 0.42838791012763977 Accuracy : 80.42426300048828 %\n","Epoch : 8 Batch : 1700 Loss : 0.8727899193763733 Accuracy : 81.05780029296875 %\n","Epoch : 9 Batch : 100 Loss : 0.4527494013309479 Accuracy : 81.0649185180664 %\n","Epoch : 9 Batch : 200 Loss : 0.8260061740875244 Accuracy : 80.88695526123047 %\n","Epoch : 9 Batch : 300 Loss : 0.36012160778045654 Accuracy : 80.5523910522461 %\n","Epoch : 9 Batch : 400 Loss : 0.4586126506328583 Accuracy : 81.25711822509766 %\n","Epoch : 9 Batch : 500 Loss : 0.876862108707428 Accuracy : 80.45985412597656 %\n","Epoch : 9 Batch : 600 Loss : 1.1250989437103271 Accuracy : 80.62357330322266 %\n","Epoch : 9 Batch : 700 Loss : 0.4249614477157593 Accuracy : 80.38866424560547 %\n","Epoch : 9 Batch : 800 Loss : 0.7390661835670471 Accuracy : 80.99373626708984 %\n","Epoch : 9 Batch : 900 Loss : 0.5914738178253174 Accuracy : 81.17881774902344 %\n","Epoch : 9 Batch : 1000 Loss : 0.8677330017089844 Accuracy : 81.5489730834961 %\n","Epoch : 9 Batch : 1100 Loss : 0.6837814450263977 Accuracy : 81.07203674316406 %\n","Epoch : 9 Batch : 1200 Loss : 1.0203278064727783 Accuracy : 81.17169952392578 %\n","Epoch : 9 Batch : 1300 Loss : 0.5245071649551392 Accuracy : 81.66999053955078 %\n","Epoch : 9 Batch : 1400 Loss : 0.7300406694412231 Accuracy : 82.17539978027344 %\n","Epoch : 9 Batch : 1500 Loss : 0.795200526714325 Accuracy : 82.0472640991211 %\n","Epoch : 9 Batch : 1600 Loss : 0.533092200756073 Accuracy : 81.51338195800781 %\n","Epoch : 9 Batch : 1700 Loss : 1.0475034713745117 Accuracy : 81.42084503173828 %\n","Epoch : 10 Batch : 100 Loss : 0.6695119738578796 Accuracy : 80.80865478515625 %\n","Epoch : 10 Batch : 200 Loss : 0.7629121541976929 Accuracy : 80.76594543457031 %\n","Epoch : 10 Batch : 300 Loss : 0.8552884459495544 Accuracy : 81.49202728271484 %\n","Epoch : 10 Batch : 400 Loss : 0.6598816514015198 Accuracy : 81.883544921875 %\n","Epoch : 10 Batch : 500 Loss : 0.418764591217041 Accuracy : 81.24288177490234 %\n","Epoch : 10 Batch : 600 Loss : 0.5251092314720154 Accuracy : 80.65205383300781 %\n","Epoch : 10 Batch : 700 Loss : 0.7103403806686401 Accuracy : 80.88695526123047 %\n","Epoch : 10 Batch : 800 Loss : 0.576575756072998 Accuracy : 81.34965515136719 %\n","Epoch : 10 Batch : 900 Loss : 1.2263696193695068 Accuracy : 82.03302764892578 %\n","Epoch : 10 Batch : 1000 Loss : 1.086423397064209 Accuracy : 81.50626373291016 %\n","Epoch : 10 Batch : 1100 Loss : 0.5970326662063599 Accuracy : 81.76964569091797 %\n","Epoch : 10 Batch : 1200 Loss : 0.7967102527618408 Accuracy : 81.9974365234375 %\n","Epoch : 10 Batch : 1300 Loss : 0.7306360006332397 Accuracy : 81.89066314697266 %\n","Epoch : 10 Batch : 1400 Loss : 0.7570853233337402 Accuracy : 80.51679992675781 %\n","Epoch : 10 Batch : 1500 Loss : 1.1695462465286255 Accuracy : 81.47779083251953 %\n","Epoch : 10 Batch : 1600 Loss : 0.7531836032867432 Accuracy : 81.49202728271484 %\n","Epoch : 10 Batch : 1700 Loss : 0.8458679914474487 Accuracy : 81.71981811523438 %\n","Epoch : 11 Batch : 100 Loss : 0.6424067616462708 Accuracy : 81.24288177490234 %\n","Epoch : 11 Batch : 200 Loss : 0.8301693797111511 Accuracy : 81.89066314697266 %\n","Epoch : 11 Batch : 300 Loss : 0.5864537954330444 Accuracy : 81.99031829833984 %\n","Epoch : 11 Batch : 400 Loss : 0.6790912747383118 Accuracy : 81.15746307373047 %\n","Epoch : 11 Batch : 500 Loss : 0.6761905550956726 Accuracy : 82.09709930419922 %\n","Epoch : 11 Batch : 600 Loss : 0.6756752729415894 Accuracy : 81.6343994140625 %\n","Epoch : 11 Batch : 700 Loss : 0.4060215651988983 Accuracy : 81.84082794189453 %\n","Epoch : 11 Batch : 800 Loss : 0.3512367010116577 Accuracy : 81.61304473876953 %\n","Epoch : 11 Batch : 900 Loss : 1.1921271085739136 Accuracy : 80.74459075927734 %\n","Epoch : 11 Batch : 1000 Loss : 1.039595365524292 Accuracy : 81.23576354980469 %\n","Epoch : 11 Batch : 1100 Loss : 0.43788787722587585 Accuracy : 81.69134521484375 %\n","Epoch : 11 Batch : 1200 Loss : 0.7612721920013428 Accuracy : 81.67710876464844 %\n","Epoch : 11 Batch : 1300 Loss : 0.56972736120224 Accuracy : 81.87642669677734 %\n","Epoch : 11 Batch : 1400 Loss : 0.8019237518310547 Accuracy : 81.29270935058594 %\n","Epoch : 11 Batch : 1500 Loss : 0.7204111814498901 Accuracy : 81.38525390625 %\n","Epoch : 11 Batch : 1600 Loss : 0.9158353209495544 Accuracy : 82.17539978027344 %\n","Epoch : 11 Batch : 1700 Loss : 0.710064709186554 Accuracy : 81.83370971679688 %\n","Epoch : 12 Batch : 100 Loss : 0.43395328521728516 Accuracy : 81.9974365234375 %\n","Epoch : 12 Batch : 200 Loss : 0.5455387830734253 Accuracy : 82.1326904296875 %\n","Epoch : 12 Batch : 300 Loss : 0.9244657158851624 Accuracy : 81.40660858154297 %\n","Epoch : 12 Batch : 400 Loss : 0.462837815284729 Accuracy : 81.78388214111328 %\n","Epoch : 12 Batch : 500 Loss : 0.76568204164505 Accuracy : 81.86219024658203 %\n","Epoch : 12 Batch : 600 Loss : 0.7087600827217102 Accuracy : 81.02220916748047 %\n","Epoch : 12 Batch : 700 Loss : 1.0247917175292969 Accuracy : 81.48490905761719 %\n","Epoch : 12 Batch : 800 Loss : 0.7675542831420898 Accuracy : 81.9974365234375 %\n","Epoch : 12 Batch : 900 Loss : 0.655659556388855 Accuracy : 82.00455474853516 %\n","Epoch : 12 Batch : 1000 Loss : 0.6585758328437805 Accuracy : 81.95472717285156 %\n","Epoch : 12 Batch : 1100 Loss : 0.6425763964653015 Accuracy : 81.39237213134766 %\n","Epoch : 12 Batch : 1200 Loss : 0.8375904560089111 Accuracy : 81.92625427246094 %\n","Epoch : 12 Batch : 1300 Loss : 0.6551761627197266 Accuracy : 82.03302764892578 %\n","Epoch : 12 Batch : 1400 Loss : 0.6081252098083496 Accuracy : 81.67710876464844 %\n","Epoch : 12 Batch : 1500 Loss : 0.8540968894958496 Accuracy : 82.39607238769531 %\n","Epoch : 12 Batch : 1600 Loss : 0.5657723546028137 Accuracy : 82.52420043945312 %\n","Epoch : 12 Batch : 1700 Loss : 0.4675925672054291 Accuracy : 82.22522735595703 %\n","Epoch : 13 Batch : 100 Loss : 0.957091748714447 Accuracy : 81.76252746582031 %\n","Epoch : 13 Batch : 200 Loss : 0.8044974207878113 Accuracy : 80.65205383300781 %\n","Epoch : 13 Batch : 300 Loss : 0.4459233283996582 Accuracy : 82.35336303710938 %\n","Epoch : 13 Batch : 400 Loss : 0.5470471978187561 Accuracy : 82.60250854492188 %\n","Epoch : 13 Batch : 500 Loss : 1.225998878479004 Accuracy : 81.82659149169922 %\n","Epoch : 13 Batch : 600 Loss : 0.9020525217056274 Accuracy : 81.66999053955078 %\n","Epoch : 13 Batch : 700 Loss : 1.0225993394851685 Accuracy : 81.96184539794922 %\n","Epoch : 13 Batch : 800 Loss : 0.45607849955558777 Accuracy : 82.40319061279297 %\n","Epoch : 13 Batch : 900 Loss : 0.849181056022644 Accuracy : 81.86219024658203 %\n","Epoch : 13 Batch : 1000 Loss : 0.6318877935409546 Accuracy : 81.80523681640625 %\n","Epoch : 13 Batch : 1100 Loss : 0.7114807367324829 Accuracy : 82.51708221435547 %\n","Epoch : 13 Batch : 1200 Loss : 0.8426674604415894 Accuracy : 81.75540924072266 %\n","Epoch : 13 Batch : 1300 Loss : 0.5914697051048279 Accuracy : 82.34624481201172 %\n","Epoch : 13 Batch : 1400 Loss : 1.0013148784637451 Accuracy : 82.18963623046875 %\n","Epoch : 13 Batch : 1500 Loss : 0.87358558177948 Accuracy : 82.11133575439453 %\n","Epoch : 13 Batch : 1600 Loss : 0.6744890809059143 Accuracy : 82.63809967041016 %\n","Epoch : 13 Batch : 1700 Loss : 1.2807022333145142 Accuracy : 82.40319061279297 %\n","Epoch : 14 Batch : 100 Loss : 0.5502092838287354 Accuracy : 82.36048126220703 %\n","Epoch : 14 Batch : 200 Loss : 0.6546286344528198 Accuracy : 82.40319061279297 %\n","Epoch : 14 Batch : 300 Loss : 0.9859906435012817 Accuracy : 82.1825180053711 %\n","Epoch : 14 Batch : 400 Loss : 1.0348014831542969 Accuracy : 82.1326904296875 %\n","Epoch : 14 Batch : 500 Loss : 0.810480535030365 Accuracy : 81.76964569091797 %\n","Epoch : 14 Batch : 600 Loss : 0.6810423135757446 Accuracy : 81.72693634033203 %\n","Epoch : 14 Batch : 700 Loss : 0.48565346002578735 Accuracy : 82.26081848144531 %\n","Epoch : 14 Batch : 800 Loss : 0.7452306747436523 Accuracy : 81.96184539794922 %\n","Epoch : 14 Batch : 900 Loss : 0.9084740877151489 Accuracy : 81.74117279052734 %\n","Epoch : 14 Batch : 1000 Loss : 0.9556750655174255 Accuracy : 81.90489959716797 %\n","Epoch : 14 Batch : 1100 Loss : 0.7911009192466736 Accuracy : 81.32830047607422 %\n","Epoch : 14 Batch : 1200 Loss : 0.6345402002334595 Accuracy : 81.86930847167969 %\n","Epoch : 14 Batch : 1300 Loss : 0.4343527853488922 Accuracy : 82.64521789550781 %\n","Epoch : 14 Batch : 1400 Loss : 0.5651953816413879 Accuracy : 82.82318115234375 %\n","Epoch : 14 Batch : 1500 Loss : 0.3314964473247528 Accuracy : 82.1326904296875 %\n","Epoch : 14 Batch : 1600 Loss : 0.7441715598106384 Accuracy : 82.39607238769531 %\n","Epoch : 14 Batch : 1700 Loss : 0.8918043971061707 Accuracy : 81.84082794189453 %\n","Epoch : 15 Batch : 100 Loss : 0.9566556811332703 Accuracy : 82.45301818847656 %\n","Epoch : 15 Batch : 200 Loss : 0.6594623923301697 Accuracy : 81.85507202148438 %\n","Epoch : 15 Batch : 300 Loss : 0.6192975640296936 Accuracy : 82.4957275390625 %\n","Epoch : 15 Batch : 400 Loss : 0.6378931999206543 Accuracy : 82.0472640991211 %\n","Epoch : 15 Batch : 500 Loss : 0.7951135039329529 Accuracy : 81.81947326660156 %\n","Epoch : 15 Batch : 600 Loss : 0.532346248626709 Accuracy : 82.32488250732422 %\n","Epoch : 15 Batch : 700 Loss : 0.8111832141876221 Accuracy : 82.5811538696289 %\n","Epoch : 15 Batch : 800 Loss : 0.5968398451805115 Accuracy : 82.61674499511719 %\n","Epoch : 15 Batch : 900 Loss : 0.9041385054588318 Accuracy : 82.92283630371094 %\n","Epoch : 15 Batch : 1000 Loss : 0.7706267237663269 Accuracy : 82.40319061279297 %\n","Epoch : 15 Batch : 1100 Loss : 0.4718881845474243 Accuracy : 81.26423645019531 %\n","Epoch : 15 Batch : 1200 Loss : 0.9457069039344788 Accuracy : 81.91913604736328 %\n","Epoch : 15 Batch : 1300 Loss : 0.9533547163009644 Accuracy : 81.883544921875 %\n","Epoch : 15 Batch : 1400 Loss : 0.9757062196731567 Accuracy : 81.84794616699219 %\n","Epoch : 15 Batch : 1500 Loss : 0.6744570732116699 Accuracy : 82.55267333984375 %\n","Epoch : 15 Batch : 1600 Loss : 0.462897926568985 Accuracy : 82.3320083618164 %\n","Epoch : 15 Batch : 1700 Loss : 0.6315682530403137 Accuracy : 82.744873046875 %\n","Epoch : 16 Batch : 100 Loss : 0.7860655188560486 Accuracy : 82.06861877441406 %\n","Epoch : 16 Batch : 200 Loss : 0.8666330575942993 Accuracy : 82.9940185546875 %\n","Epoch : 16 Batch : 300 Loss : 0.7809591889381409 Accuracy : 82.20387268066406 %\n","Epoch : 16 Batch : 400 Loss : 0.9188646078109741 Accuracy : 82.35336303710938 %\n","Epoch : 16 Batch : 500 Loss : 0.6100082397460938 Accuracy : 82.83741760253906 %\n","Epoch : 16 Batch : 600 Loss : 0.4736170470714569 Accuracy : 82.85165405273438 %\n","Epoch : 16 Batch : 700 Loss : 0.6027712821960449 Accuracy : 81.52761840820312 %\n","Epoch : 16 Batch : 800 Loss : 1.052909255027771 Accuracy : 81.02932739257812 %\n","Epoch : 16 Batch : 900 Loss : 0.5419561862945557 Accuracy : 82.16828155517578 %\n","Epoch : 16 Batch : 1000 Loss : 0.8846708536148071 Accuracy : 81.82659149169922 %\n","Epoch : 16 Batch : 1100 Loss : 0.8203051686286926 Accuracy : 82.38895416259766 %\n","Epoch : 16 Batch : 1200 Loss : 0.4789222478866577 Accuracy : 82.23234558105469 %\n","Epoch : 16 Batch : 1300 Loss : 0.4542407989501953 Accuracy : 82.4458999633789 %\n","Epoch : 16 Batch : 1400 Loss : 0.8543949127197266 Accuracy : 81.5632095336914 %\n","Epoch : 16 Batch : 1500 Loss : 0.5406419038772583 Accuracy : 82.39607238769531 %\n","Epoch : 16 Batch : 1600 Loss : 0.3485974967479706 Accuracy : 82.3818359375 %\n","Epoch : 16 Batch : 1700 Loss : 0.5663846731185913 Accuracy : 82.43878173828125 %\n","Epoch : 17 Batch : 100 Loss : 0.8570728302001953 Accuracy : 82.64521789550781 %\n","Epoch : 17 Batch : 200 Loss : 0.9209353923797607 Accuracy : 82.42454528808594 %\n","Epoch : 17 Batch : 300 Loss : 0.6998279690742493 Accuracy : 82.9441909790039 %\n","Epoch : 17 Batch : 400 Loss : 0.664037823677063 Accuracy : 82.59539031982422 %\n","Epoch : 17 Batch : 500 Loss : 0.8681570291519165 Accuracy : 82.27505493164062 %\n","Epoch : 17 Batch : 600 Loss : 1.0558741092681885 Accuracy : 82.75910949707031 %\n","Epoch : 17 Batch : 700 Loss : 0.8959051370620728 Accuracy : 82.21099090576172 %\n","Epoch : 17 Batch : 800 Loss : 0.483905553817749 Accuracy : 82.68792724609375 %\n","Epoch : 17 Batch : 900 Loss : 0.6444517970085144 Accuracy : 83.13639068603516 %\n","Epoch : 17 Batch : 1000 Loss : 0.9672913551330566 Accuracy : 82.95130920410156 %\n","Epoch : 17 Batch : 1100 Loss : 0.7178328633308411 Accuracy : 81.66287231445312 %\n","Epoch : 17 Batch : 1200 Loss : 0.5811488628387451 Accuracy : 81.82659149169922 %\n","Epoch : 17 Batch : 1300 Loss : 0.807452917098999 Accuracy : 82.57403564453125 %\n","Epoch : 17 Batch : 1400 Loss : 0.8603929877281189 Accuracy : 82.10421752929688 %\n","Epoch : 17 Batch : 1500 Loss : 0.72857266664505 Accuracy : 82.6950454711914 %\n","Epoch : 17 Batch : 1600 Loss : 0.7412562966346741 Accuracy : 83.00825500488281 %\n","Epoch : 17 Batch : 1700 Loss : 0.8514503240585327 Accuracy : 83.0794448852539 %\n","Epoch : 18 Batch : 100 Loss : 0.8573232889175415 Accuracy : 82.14692687988281 %\n","Epoch : 18 Batch : 200 Loss : 0.5088507533073425 Accuracy : 83.54926300048828 %\n","Epoch : 18 Batch : 300 Loss : 0.7679250240325928 Accuracy : 82.78758239746094 %\n","Epoch : 18 Batch : 400 Loss : 0.6916892528533936 Accuracy : 83.41400909423828 %\n","Epoch : 18 Batch : 500 Loss : 0.5731101632118225 Accuracy : 82.76622772216797 %\n","Epoch : 18 Batch : 600 Loss : 1.079360842704773 Accuracy : 82.88724517822266 %\n","Epoch : 18 Batch : 700 Loss : 0.8107967376708984 Accuracy : 82.11133575439453 %\n","Epoch : 18 Batch : 800 Loss : 0.6050130128860474 Accuracy : 81.33541870117188 %\n","Epoch : 18 Batch : 900 Loss : 1.0183801651000977 Accuracy : 83.47095489501953 %\n","Epoch : 18 Batch : 1000 Loss : 0.8617386221885681 Accuracy : 82.27505493164062 %\n","Epoch : 18 Batch : 1100 Loss : 0.8223016262054443 Accuracy : 82.46725463867188 %\n","Epoch : 18 Batch : 1200 Loss : 0.5775198936462402 Accuracy : 81.9333724975586 %\n","Epoch : 18 Batch : 1300 Loss : 0.7351638078689575 Accuracy : 83.05096435546875 %\n","Epoch : 18 Batch : 1400 Loss : 0.4237346351146698 Accuracy : 82.85877227783203 %\n","Epoch : 18 Batch : 1500 Loss : 0.6508147716522217 Accuracy : 83.21469116210938 %\n","Epoch : 18 Batch : 1600 Loss : 0.9619705677032471 Accuracy : 82.6950454711914 %\n","Epoch : 18 Batch : 1700 Loss : 0.5830259323120117 Accuracy : 82.46013641357422 %\n","Epoch : 19 Batch : 100 Loss : 0.7158569693565369 Accuracy : 82.70216369628906 %\n","Epoch : 19 Batch : 200 Loss : 0.6501234173774719 Accuracy : 82.95130920410156 %\n","Epoch : 19 Batch : 300 Loss : 0.5999778509140015 Accuracy : 82.3320083618164 %\n","Epoch : 19 Batch : 400 Loss : 0.5471526384353638 Accuracy : 82.90859985351562 %\n","Epoch : 19 Batch : 500 Loss : 0.6850183010101318 Accuracy : 82.16116333007812 %\n","Epoch : 19 Batch : 600 Loss : 0.6997348070144653 Accuracy : 83.16486358642578 %\n","Epoch : 19 Batch : 700 Loss : 0.9358450770378113 Accuracy : 82.2964096069336 %\n","Epoch : 19 Batch : 800 Loss : 0.4484352767467499 Accuracy : 83.25028228759766 %\n","Epoch : 19 Batch : 900 Loss : 0.5989399552345276 Accuracy : 83.05809020996094 %\n","Epoch : 19 Batch : 1000 Loss : 0.7609516382217407 Accuracy : 82.41030883789062 %\n","Epoch : 19 Batch : 1100 Loss : 0.584919810295105 Accuracy : 83.0652084350586 %\n","Epoch : 19 Batch : 1200 Loss : 0.48024335503578186 Accuracy : 81.96896362304688 %\n","Epoch : 19 Batch : 1300 Loss : 0.603507399559021 Accuracy : 82.80181884765625 %\n","Epoch : 19 Batch : 1400 Loss : 0.6412165760993958 Accuracy : 83.2431640625 %\n","Epoch : 19 Batch : 1500 Loss : 1.1784030199050903 Accuracy : 83.17198181152344 %\n","Epoch : 19 Batch : 1600 Loss : 0.5159887671470642 Accuracy : 81.79100036621094 %\n","Epoch : 19 Batch : 1700 Loss : 0.6931058168411255 Accuracy : 82.45301818847656 %\n","Epoch : 20 Batch : 100 Loss : 0.5924717783927917 Accuracy : 82.41742706298828 %\n","Epoch : 20 Batch : 200 Loss : 1.0690892934799194 Accuracy : 82.89436340332031 %\n","Epoch : 20 Batch : 300 Loss : 0.7628279328346252 Accuracy : 83.07232666015625 %\n","Epoch : 20 Batch : 400 Loss : 0.7517132759094238 Accuracy : 82.880126953125 %\n","Epoch : 20 Batch : 500 Loss : 0.6660258769989014 Accuracy : 82.36759948730469 %\n","Epoch : 20 Batch : 600 Loss : 0.9800891876220703 Accuracy : 82.1967544555664 %\n","Epoch : 20 Batch : 700 Loss : 0.6262010931968689 Accuracy : 82.98690032958984 %\n","Epoch : 20 Batch : 800 Loss : 0.4736785888671875 Accuracy : 83.41400909423828 %\n","Epoch : 20 Batch : 900 Loss : 1.0297573804855347 Accuracy : 82.53131866455078 %\n","Epoch : 20 Batch : 1000 Loss : 0.525140106678009 Accuracy : 82.39607238769531 %\n","Epoch : 20 Batch : 1100 Loss : 0.9419043064117432 Accuracy : 82.9299545288086 %\n","Epoch : 20 Batch : 1200 Loss : 0.6676971316337585 Accuracy : 83.08656311035156 %\n","Epoch : 20 Batch : 1300 Loss : 0.47649821639060974 Accuracy : 81.47067260742188 %\n","Epoch : 20 Batch : 1400 Loss : 0.6760737895965576 Accuracy : 83.0438461303711 %\n","Epoch : 20 Batch : 1500 Loss : 0.6306536197662354 Accuracy : 81.42796325683594 %\n","Epoch : 20 Batch : 1600 Loss : 0.9796375036239624 Accuracy : 83.28587341308594 %\n","Epoch : 20 Batch : 1700 Loss : 0.5195794701576233 Accuracy : 82.23946380615234 %\n","Epoch : 21 Batch : 100 Loss : 0.4699690043926239 Accuracy : 82.35336303710938 %\n","Epoch : 21 Batch : 200 Loss : 0.7245634198188782 Accuracy : 82.15404510498047 %\n","Epoch : 21 Batch : 300 Loss : 0.7249270081520081 Accuracy : 81.77676391601562 %\n","Epoch : 21 Batch : 400 Loss : 0.6554064750671387 Accuracy : 82.26793670654297 %\n","Epoch : 21 Batch : 500 Loss : 0.6810396909713745 Accuracy : 83.1933364868164 %\n","Epoch : 21 Batch : 600 Loss : 0.5037459135055542 Accuracy : 83.03672790527344 %\n","Epoch : 21 Batch : 700 Loss : 0.6262277364730835 Accuracy : 82.70216369628906 %\n","Epoch : 21 Batch : 800 Loss : 0.4279842972755432 Accuracy : 83.14350891113281 %\n","Epoch : 21 Batch : 900 Loss : 0.4435889720916748 Accuracy : 82.90148162841797 %\n","Epoch : 21 Batch : 1000 Loss : 0.5611915588378906 Accuracy : 83.42112731933594 %\n","Epoch : 21 Batch : 1100 Loss : 0.7279679179191589 Accuracy : 83.37129974365234 %\n","Epoch : 21 Batch : 1200 Loss : 0.7427867650985718 Accuracy : 83.15062713623047 %\n","Epoch : 21 Batch : 1300 Loss : 0.7850027680397034 Accuracy : 83.20757293701172 %\n","Epoch : 21 Batch : 1400 Loss : 0.4949926435947418 Accuracy : 83.05096435546875 %\n","Epoch : 21 Batch : 1500 Loss : 0.4584086835384369 Accuracy : 82.92283630371094 %\n","Epoch : 21 Batch : 1600 Loss : 0.7935609221458435 Accuracy : 82.9940185546875 %\n","Epoch : 21 Batch : 1700 Loss : 0.6714265942573547 Accuracy : 83.20757293701172 %\n","Epoch : 22 Batch : 100 Loss : 1.0699769258499146 Accuracy : 83.05096435546875 %\n","Epoch : 22 Batch : 200 Loss : 0.6178033947944641 Accuracy : 83.0652084350586 %\n","Epoch : 22 Batch : 300 Loss : 0.6783271431922913 Accuracy : 83.75569152832031 %\n","Epoch : 22 Batch : 400 Loss : 0.7507221698760986 Accuracy : 83.36418151855469 %\n","Epoch : 22 Batch : 500 Loss : 0.7688964605331421 Accuracy : 83.39977264404297 %\n","Epoch : 22 Batch : 600 Loss : 1.2459838390350342 Accuracy : 81.98320007324219 %\n","Epoch : 22 Batch : 700 Loss : 0.548222541809082 Accuracy : 83.68450927734375 %\n","Epoch : 22 Batch : 800 Loss : 0.2672646641731262 Accuracy : 83.72010040283203 %\n","Epoch : 22 Batch : 900 Loss : 0.9496762752532959 Accuracy : 82.46725463867188 %\n","Epoch : 22 Batch : 1000 Loss : 0.6626073718070984 Accuracy : 83.05809020996094 %\n","Epoch : 22 Batch : 1100 Loss : 0.559685230255127 Accuracy : 83.00113677978516 %\n","Epoch : 22 Batch : 1200 Loss : 1.1061376333236694 Accuracy : 83.25740051269531 %\n","Epoch : 22 Batch : 1300 Loss : 0.42415064573287964 Accuracy : 83.01537322998047 %\n","Epoch : 22 Batch : 1400 Loss : 0.5305166244506836 Accuracy : 82.5455551147461 %\n","Epoch : 22 Batch : 1500 Loss : 0.710411012172699 Accuracy : 83.77705383300781 %\n","Epoch : 22 Batch : 1600 Loss : 0.8379414081573486 Accuracy : 83.64891815185547 %\n","Epoch : 22 Batch : 1700 Loss : 0.7949845790863037 Accuracy : 83.76280975341797 %\n","Epoch : 23 Batch : 100 Loss : 0.5590371489524841 Accuracy : 83.41400909423828 %\n","Epoch : 23 Batch : 200 Loss : 0.3748600482940674 Accuracy : 83.52790069580078 %\n","Epoch : 23 Batch : 300 Loss : 0.4305253028869629 Accuracy : 83.95500946044922 %\n","Epoch : 23 Batch : 400 Loss : 0.7768546938896179 Accuracy : 83.69874572753906 %\n","Epoch : 23 Batch : 500 Loss : 0.5624836683273315 Accuracy : 82.86589050292969 %\n","Epoch : 23 Batch : 600 Loss : 0.5534989237785339 Accuracy : 83.59197235107422 %\n","Epoch : 23 Batch : 700 Loss : 0.26056742668151855 Accuracy : 83.34994506835938 %\n","Epoch : 23 Batch : 800 Loss : 0.6802257299423218 Accuracy : 83.15062713623047 %\n","Epoch : 23 Batch : 900 Loss : 0.4544285535812378 Accuracy : 83.27163696289062 %\n","Epoch : 23 Batch : 1000 Loss : 1.0418444871902466 Accuracy : 83.62044525146484 %\n","Epoch : 23 Batch : 1100 Loss : 0.640690267086029 Accuracy : 83.20045471191406 %\n","Epoch : 23 Batch : 1200 Loss : 0.5578916072845459 Accuracy : 83.39977264404297 %\n","Epoch : 23 Batch : 1300 Loss : 0.7106650471687317 Accuracy : 83.1791000366211 %\n","Epoch : 23 Batch : 1400 Loss : 1.1243048906326294 Accuracy : 83.27163696289062 %\n","Epoch : 23 Batch : 1500 Loss : 0.4872892200946808 Accuracy : 83.64179992675781 %\n","Epoch : 23 Batch : 1600 Loss : 0.6303846836090088 Accuracy : 82.05438232421875 %\n","Epoch : 23 Batch : 1700 Loss : 0.6302134990692139 Accuracy : 83.12215423583984 %\n","Epoch : 24 Batch : 100 Loss : 0.9671661257743835 Accuracy : 83.62044525146484 %\n","Epoch : 24 Batch : 200 Loss : 0.8052201867103577 Accuracy : 83.66315460205078 %\n","Epoch : 24 Batch : 300 Loss : 0.49405553936958313 Accuracy : 83.68450927734375 %\n","Epoch : 24 Batch : 400 Loss : 0.5775824785232544 Accuracy : 83.86959075927734 %\n","Epoch : 24 Batch : 500 Loss : 0.28837037086486816 Accuracy : 83.23604583740234 %\n","Epoch : 24 Batch : 600 Loss : 0.7541680335998535 Accuracy : 83.81976318359375 %\n","Epoch : 24 Batch : 700 Loss : 0.9015101194381714 Accuracy : 83.72010040283203 %\n","Epoch : 24 Batch : 800 Loss : 0.29308420419692993 Accuracy : 83.96924591064453 %\n","Epoch : 24 Batch : 900 Loss : 0.5223386883735657 Accuracy : 83.53502655029297 %\n","Epoch : 24 Batch : 1000 Loss : 0.5506168603897095 Accuracy : 82.65945434570312 %\n","Epoch : 24 Batch : 1100 Loss : 0.7107140421867371 Accuracy : 83.12215423583984 %\n","Epoch : 24 Batch : 1200 Loss : 0.24282076954841614 Accuracy : 83.1791000366211 %\n","Epoch : 24 Batch : 1300 Loss : 0.9087755680084229 Accuracy : 84.02619934082031 %\n","Epoch : 24 Batch : 1400 Loss : 1.0779598951339722 Accuracy : 83.76992797851562 %\n","Epoch : 24 Batch : 1500 Loss : 0.391154408454895 Accuracy : 83.38553619384766 %\n","Epoch : 24 Batch : 1600 Loss : 0.8183070421218872 Accuracy : 83.4282455444336 %\n","Epoch : 24 Batch : 1700 Loss : 0.9195982813835144 Accuracy : 83.15062713623047 %\n","Epoch : 25 Batch : 100 Loss : 0.5138708353042603 Accuracy : 83.1933364868164 %\n","Epoch : 25 Batch : 200 Loss : 1.1654678583145142 Accuracy : 82.97266387939453 %\n","Epoch : 25 Batch : 300 Loss : 0.8952689170837402 Accuracy : 83.05096435546875 %\n","Epoch : 25 Batch : 400 Loss : 0.47575700283050537 Accuracy : 83.27163696289062 %\n","Epoch : 25 Batch : 500 Loss : 0.7791721224784851 Accuracy : 84.13297271728516 %\n","Epoch : 25 Batch : 600 Loss : 0.6530553102493286 Accuracy : 83.55638122558594 %\n","Epoch : 25 Batch : 700 Loss : 0.69586181640625 Accuracy : 82.95130920410156 %\n","Epoch : 25 Batch : 800 Loss : 0.8007293939590454 Accuracy : 83.03672790527344 %\n","Epoch : 25 Batch : 900 Loss : 0.7966340184211731 Accuracy : 82.93707275390625 %\n","Epoch : 25 Batch : 1000 Loss : 0.4572705924510956 Accuracy : 83.1791000366211 %\n","Epoch : 25 Batch : 1100 Loss : 0.484418123960495 Accuracy : 83.0652084350586 %\n","Epoch : 25 Batch : 1200 Loss : 0.6498052477836609 Accuracy : 84.05467224121094 %\n","Epoch : 25 Batch : 1300 Loss : 0.8374009728431702 Accuracy : 83.43536376953125 %\n","Epoch : 25 Batch : 1400 Loss : 0.7242506742477417 Accuracy : 83.85535430908203 %\n","Epoch : 25 Batch : 1500 Loss : 0.49923431873321533 Accuracy : 83.16486358642578 %\n","Epoch : 25 Batch : 1600 Loss : 0.5187028050422668 Accuracy : 83.68450927734375 %\n","Epoch : 25 Batch : 1700 Loss : 0.7970827221870422 Accuracy : 83.96212768554688 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z40OQIj1p9ZC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U_gf6jlRaFtA","colab_type":"text"},"source":["#4.Kaggle Submission"]},{"cell_type":"code","metadata":{"id":"oxZYhm8oaLOF","colab_type":"code","colab":{}},"source":["index = range(0,test_ds2.test_len)\n","columns = ['ImageId','Label']\n","df = pd.DataFrame(index=index,columns=columns)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8Hzq7UxbHXo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"82781ac0-d481-45b9-db6e-96edcf7159dd","executionInfo":{"status":"ok","timestamp":1578039406064,"user_tz":360,"elapsed":4364,"user":{"displayName":"Jonathan Hrach","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvQOBdkCsJ8wR615JkhkNVRVrDOP8rjSLHRJ2lAQ=s64","userId":"12030830714702100809"}}},"source":["for i, data in enumerate(test_dl, 0):\n","    images = data\n","    images = images.cuda()\n","    print(images.size())\n","    out = net(images)\n","    _, predicted = torch.max(out, 1)\n","    print(predicted.size())\n","    #print(predicted[0].item())\n","    for j in range(predicted.size()[0]):\n","        df.iloc[j,:] = [j,predicted[j].item()] "],"execution_count":150,"outputs":[{"output_type":"stream","text":["torch.Size([5000, 3, 28, 28])\n","torch.Size([5000])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e9DJ-uT-cqn7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":266},"outputId":"18667223-3d06-4a59-adbe-4c564ca95e5a","executionInfo":{"status":"ok","timestamp":1578039406894,"user_tz":360,"elapsed":236,"user":{"displayName":"Jonathan Hrach","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvQOBdkCsJ8wR615JkhkNVRVrDOP8rjSLHRJ2lAQ=s64","userId":"12030830714702100809"}}},"source":["print(df)"],"execution_count":151,"outputs":[{"output_type":"stream","text":["      ImageId  Label\n","0           0      3\n","1           1      0\n","2           2      6\n","3           3      6\n","4           4      7\n","...       ...    ...\n","4995     4995      1\n","4996     4996      0\n","4997     4997      1\n","4998     4998      6\n","4999     4999      3\n","\n","[5000 rows x 2 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mug24kbyeywf","colab_type":"code","colab":{}},"source":["df.to_csv('submission.csv',index=False)"],"execution_count":0,"outputs":[]}]}